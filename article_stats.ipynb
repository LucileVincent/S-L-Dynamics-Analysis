{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of the database : NDC, CCDB and IFADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from snl_stats_extraction_data import *\n",
    "from snl_stats_extraction_data import give_mimicry_folder4\n",
    "DIR, databases_pair_paths, databases_paths, tier_lists, databases, databases_pairs, tiers = get_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "databases_name = [key.replace('_paths','').upper() for key in databases.keys()]\n",
    "databases_pairs = [key for key in databases_pairs.keys()]\n",
    "expressions = [\"Smiles_0\", \"Laughs_0\"]\n",
    "# entities = {expression : tier_lists[expression] for expression in expressions}\n",
    "laughs_intensities = tier_lists['Laughs_0']\n",
    "smiles_intensities = tier_lists['Smiles_0']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Mimicry (inter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the capacity of someone to mimic someone else expression in an interaction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, an event is mimicry when the same expression is replicated. For the purpose of this study, and to analyse the influence of two expressions on each other (smiles and laughs), the definition is extended to copying different expressions as well, i.e., smiles mimicking laughs and vice versa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus calculate the mimicry of each expression at a given intensity on another, for spk on lsn and vice versa for a delta = 1000 ms (automatic mimicry). We look at person B mimicking A (A/B) and vice versa between pairs files in order to see if it has an impact on the result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation of delta :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic (also called unconscious or reflexive) mimicry occurs unconsciously and quickly, usually within 1000 ms of seeing a facial expression, while effortful mimicry (also called intentional or voluntary) involves a slower conscious effort to reproduce the facial expression of another.\n",
    "- Automatic mimicry occurs without awareness and is considered an innate aspect of human nature that plays a key role in social interactions.\n",
    "- Effortful facial mimicry, or the deliberate act of copying another person's facial expression (for example, being told explicitly to mimic a photograph), is primarily distinguished from automatic mimicry as a conscious process ( versus unconscious)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) B mimicking A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with person B mimicking A in an interaction (so all second files in the pairs files mimicking first files in database order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B -> person B mimics person A\n",
    "mimic_choice = 'A/B' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Mimicry Smiles vs Laughs (all entities) for each database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of the stats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database==databases_pairs[i].replace('_pairs','').upper():\n",
    "                databases_list=databases_pair_paths[databases_pairs[i]]\n",
    "    # Create a 2x2 matrix with zeros\n",
    "    probabilities_matrix = np.zeros((len(expressions), len(expressions)))\n",
    "    for j in range(len(expressions)):\n",
    "        expression_choiceA = expressions[j]\n",
    "        for k in range(len(expressions)):\n",
    "            expression_choiceB = expressions[k]\n",
    "            list_mimicry_SL = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, delta_t=delta, mimic_choice=mimic_choice)\n",
    "            for item in list_mimicry_SL:\n",
    "                 moyenne_prob_interaction += item[1]\n",
    "            moyenne_prob_interaction = moyenne_prob_interaction/len(list_mimicry_SL)\n",
    "            probabilities_matrix[j, k] = moyenne_prob_interaction\n",
    "            moyenne_prob_interaction = 0\n",
    "\n",
    "    # Create a new figure for each database\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create the heatmap plot\n",
    "    im = ax.imshow(probabilities_matrix, cmap='YlGnBu', interpolation='nearest')\n",
    "    \n",
    "    # Add the probability values within each square\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color = 'black'  # Default text color\n",
    "            ax.text(y, x, f'{probabilities_matrix[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "    \n",
    "    # Customize the plot\n",
    "    fig.colorbar(im, ax=ax, label='Probability')\n",
    "    ax.set_xticks(range(len(expressions)))\n",
    "    ax.set_yticks(range(len(expressions)))\n",
    "    ax.set_xticklabels(expressions)\n",
    "    ax.set_yticklabels(expressions)\n",
    "    ax.set_title(f'Mean mimicry probability heatmap of Smiles or Laughs following Smiles or Laughs in an interaction - {database}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the stats:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For A\\B:\n",
    "We first observe that, in general, laughs are mostly mimicked by smiles and laughs (except for ifadv) while smiles are mimicked by smiles mostly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Mimicry Smiles vs Laughs (per entity) for each database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of the stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_2 = []\n",
    "moyenne_prob_interaction_2 = 0\n",
    "\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "    \n",
    "    # Create a matrix with zeros\n",
    "    num_entities_A = sum(len(tier_lists[expression_choiceA]) for expression_choiceA in expressions)\n",
    "    num_entities_B = sum(len(tier_lists[expression_choiceB]) for expression_choiceB in expressions)\n",
    "    probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "    \n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "    \n",
    "    for j in range(len(expressions)):\n",
    "        expression_choiceA = expressions[j]\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        \n",
    "        for entityA in entitiesA:\n",
    "            for k in range(len(expressions)):\n",
    "                expression_choiceB = expressions[k]\n",
    "                entitiesB = tier_lists[expression_choiceB]\n",
    "                \n",
    "                for entityB in entitiesB:\n",
    "                    list_mimicry_SL_entity = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, 'Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice)\n",
    "                    \n",
    "                    for item in list_mimicry_SL_entity:\n",
    "                        moyenne_prob_interaction_2 += item[1]\n",
    "                    \n",
    "                    moyenne_prob_interaction_2 = moyenne_prob_interaction_2 / len(list_mimicry_SL_entity)\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_2\n",
    "                    moyenne_prob_interaction_2 = 0\n",
    "                    \n",
    "                    current_col += 1\n",
    "            \n",
    "            current_row += 1\n",
    "            current_col = 0\n",
    "    \n",
    "    # Create a new figure for each database\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create the heatmap plot\n",
    "    im = ax.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "    \n",
    "    # Add the probability values within each square\n",
    "    for x in range(num_entities_A):\n",
    "        for y in range(num_entities_B):\n",
    "            text_color = 'black'  # Default text color\n",
    "            ax.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "    \n",
    "    # Customize the plot\n",
    "    fig.colorbar(im, ax=ax, label='Probability')\n",
    "    \n",
    "    # Set the x and y ticks and labels based on the number of entities\n",
    "    xticks = np.arange(num_entities_B)\n",
    "    yticks = np.arange(num_entities_A)\n",
    "    \n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "    \n",
    "    # Set the x and y tick labels based on the expressions and entities\n",
    "    xtick_labels = []\n",
    "    ytick_labels = []\n",
    "    \n",
    "    for expression_choiceB in expressions:\n",
    "        entitiesB = tier_lists[expression_choiceB]\n",
    "        xtick_labels.extend(entitiesB)\n",
    "    \n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        ytick_labels.extend(entitiesA)\n",
    "    \n",
    "    ax.set_xticklabels(xtick_labels, rotation=90)\n",
    "    ax.set_yticklabels(ytick_labels)\n",
    "    \n",
    "    ax.set_title(f'Mean mimicry probability heatmap during an interaction - {database}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_2 = []\n",
    "moyenne_prob_interaction_2 = 0\n",
    "\n",
    "\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "    \n",
    "    # Create a dictionary to store entities grouped by expressions\n",
    "    entities_by_expression = {}\n",
    "\n",
    "    # Group entities by expressions\n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        for entityA in entitiesA:\n",
    "            if expression_choiceA not in entities_by_expression:\n",
    "                entities_by_expression[expression_choiceA] = []\n",
    "            entities_by_expression[expression_choiceA].append(entityA)\n",
    "\n",
    "    # Iterate over expression pairs and entities for each database\n",
    "    for expression_choiceA, entitiesA in entities_by_expression.items():\n",
    "        for expression_choiceB, entitiesB in entities_by_expression.items():\n",
    "            # Create a matrix with zeros\n",
    "            num_entities_A = len(entitiesA)\n",
    "            num_entities_B = len(entitiesB)\n",
    "            probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "\n",
    "            # Track the current row and column index\n",
    "            current_row = 0\n",
    "            current_col = 0\n",
    "\n",
    "            for entityA in entitiesA:\n",
    "                for entityB in entitiesB:\n",
    "                    list_mimicry_SL_entity = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, 'Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice)\n",
    "\n",
    "                    for item in list_mimicry_SL_entity:\n",
    "                        moyenne_prob_interaction_2 += item[1]\n",
    "\n",
    "                    moyenne_prob_interaction_2 = moyenne_prob_interaction_2 / len(list_mimicry_SL_entity)\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_2\n",
    "                    moyenne_prob_interaction_2 = 0\n",
    "\n",
    "                    current_col += 1\n",
    "\n",
    "                current_row += 1\n",
    "                current_col = 0\n",
    "\n",
    "            # Create a new figure for each expression pair and database\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "            # Create the heatmap plot\n",
    "            im = ax.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "            # Add the probability values within each square\n",
    "            for x in range(num_entities_A):\n",
    "                for y in range(num_entities_B):\n",
    "                    text_color = 'black'\n",
    "                    ax.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "\n",
    "            # Customize the plot\n",
    "            fig.colorbar(im, ax=ax, label='Probability')\n",
    "\n",
    "            # Set the x and y ticks and labels based on the number of entities\n",
    "            xticks = np.arange(num_entities_B)\n",
    "            yticks = np.arange(num_entities_A)\n",
    "\n",
    "            ax.set_xticks(xticks)\n",
    "            ax.set_yticks(yticks)\n",
    "\n",
    "            # Set the x and y tick labels based on the entities\n",
    "            ax.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax.set_yticklabels(entitiesA)\n",
    "\n",
    "            ax.set_xlabel(expression_choiceB)\n",
    "            ax.set_ylabel(expression_choiceA)\n",
    "            ax.set_title(f'Mean mimicry probability heatmap during an interaction - {database}')\n",
    "\n",
    "            # Show the plot\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_2 = []\n",
    "moyenne_prob_interaction_2 = 0\n",
    "\n",
    "# Iterate over each database\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Create a new dictionary to store entities grouped by expressions for each database\n",
    "    entities_by_expression = {}\n",
    "\n",
    "    # Group entities by expressions\n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        for entityA in entitiesA:\n",
    "            if expression_choiceA not in entities_by_expression:\n",
    "                entities_by_expression[expression_choiceA] = []\n",
    "            entities_by_expression[expression_choiceA].append(entityA)\n",
    "\n",
    "    # Iterate over expression pairs and entities for each database\n",
    "    for j, (expression_choiceA, entitiesA) in enumerate(entities_by_expression.items()):\n",
    "        for k, (expression_choiceB, entitiesB) in enumerate(entities_by_expression.items()):\n",
    "            # Create a matrix with zeros\n",
    "            num_entities_A = len(entitiesA)\n",
    "            num_entities_B = len(entitiesB)\n",
    "            probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "\n",
    "            # Track the current row and column index\n",
    "            current_row = 0\n",
    "            current_col = 0\n",
    "\n",
    "            for entityA in entitiesA:\n",
    "                for entityB in entitiesB:\n",
    "                    list_mimicry_SL_entity = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, 'Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice)\n",
    "\n",
    "                    for item in list_mimicry_SL_entity:\n",
    "                        moyenne_prob_interaction_2 += item[1]\n",
    "\n",
    "                    moyenne_prob_interaction_2 = moyenne_prob_interaction_2 / len(list_mimicry_SL_entity)\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_2\n",
    "                    moyenne_prob_interaction_2 = 0\n",
    "\n",
    "                    current_col += 1\n",
    "\n",
    "                current_row += 1\n",
    "                current_col = 0\n",
    "\n",
    "            # Select the appropriate subplot for each heatmap\n",
    "            ax = axs[j, k]\n",
    "\n",
    "            # Create the heatmap plot\n",
    "            im = ax.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "            # Add the probability values within each square\n",
    "            for x in range(num_entities_A):\n",
    "                for y in range(num_entities_B):\n",
    "                    text_color = 'black'\n",
    "                    ax.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "\n",
    "            # Customize the plot\n",
    "            ax.set_xticks(np.arange(num_entities_B))\n",
    "            ax.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax.set_yticks(np.arange(num_entities_A))\n",
    "            ax.set_yticklabels(entitiesA)\n",
    "            ax.set_xlabel(expression_choiceB)\n",
    "            ax.set_ylabel(expression_choiceA)\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the heatmaps of each database\n",
    "    fig.suptitle(f'Mean mimicry probability heatmaps during an interaction for {database}', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the stats:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For A/B:\n",
    " Then, when laughs mimic smiles, the levels of laughs are lower for CCDB, IFADV while for NDC, we observe that even if the levels of laughs are generally lower, we can also have : a low level of smiles mimicked by a high level of laughs (25%), a subtle smile mimicked by a low laugh (27%).\n",
    " On the other hand, when smiles mimic laughs the smile levels are higher even if this type of mimicking is rarer.\n",
    " For smiles mimicking smiles, the levels mimicked have similar values.  \n",
    " And for laughs imitating laughs: mimicked levels are mostly lower for CCDB, highly variable for NDC and non-existent for IVADV.\n",
    " Lower levels of laughs mimicking smiles and higher levels of smiles mimicking laughs are in favor of the smile-laugh continuum theory mentioned earlier with smiles being on the low arousal side and laughs on the high side of a common arousal level scale for both S&L."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered by role "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we look at S&L mimicry in relation to the role of the mimicker (listener or speaker)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For all entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "entity_pairs = [(\"spk\", \"lsn\"), (\"lsn\", \"spk\")]\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database==databases_pairs[i].replace('_pairs','').upper():\n",
    "                databases_list=databases_pair_paths[databases_pairs[i]]\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "\n",
    "    # Create a 2x2 matrix with zeros\n",
    "    probabilities_matrix_1 = np.zeros((len(expressions), len(expressions)))\n",
    "    probabilities_matrix_2 = np.zeros((len(expressions), len(expressions)))\n",
    "    for j in range(len(expressions)):\n",
    "        expression_choiceA = expressions[j]\n",
    "        for k in range(len(expressions)):\n",
    "            expression_choiceB = expressions[k]\n",
    "            for pair_index, (entityA, entityB) in enumerate(entity_pairs):\n",
    "                # Get the statistics for each entity of Role (spk or lsn)\n",
    "                list_mimicry_SL_by_role = give_mimicry_folder4(databases_list, database.lower(), get_tier_from_tier, get_tier_from_tier, expression_choiceA, expression_choiceB, tier_filter='Role', entity1=entityA, entity2=entityB, delta_t=delta, mimic_choice=mimic_choice)\n",
    "                moyenne_prob_interaction = 0\n",
    "                for item in list_mimicry_SL_by_role:\n",
    "                    moyenne_prob_interaction += item[1]\n",
    "                moyenne_prob_interaction = moyenne_prob_interaction/len(list_mimicry_SL_by_role)\n",
    "                if entityA == \"spk\":\n",
    "                    probabilities_matrix_1[current_row, current_col] = moyenne_prob_interaction\n",
    "                elif entityA == \"lsn\":\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction\n",
    "\n",
    "            current_col += 1\n",
    "\n",
    "        current_row += 1\n",
    "        current_col = 0\n",
    "    # Create the heatmaps for spk and lsn\n",
    "    im_spk = axs[0].imshow(probabilities_matrix_1, cmap='YlGnBu', interpolation='nearest')\n",
    "    im_lsn = axs[1].imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "    # Add the probability values within each square for spk\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color_spk = 'black'\n",
    "            axs[0].text(y, x, f'{probabilities_matrix_1[x, y]:.5f}', ha='center', va='center', color=text_color_spk)\n",
    "\n",
    "    # Add the probability values within each square for lsn\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color_lsn = 'black'\n",
    "            axs[1].text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color_lsn)\n",
    "\n",
    "    # Customize the plots for spk and lsn\n",
    "    axs[0].set_xticks(range(len(expressions)))\n",
    "    axs[0].set_yticks(range(len(expressions)))\n",
    "    axs[0].set_xticklabels(['Smiles lsn', 'Laughs lsn'])\n",
    "    axs[0].set_yticklabels(['Smiles spk', 'Laughs spk'])\n",
    "    \n",
    "\n",
    "    axs[1].set_xticks(range(len(expressions)))\n",
    "    axs[1].set_yticks(range(len(expressions)))\n",
    "    axs[1].set_xticklabels(['Smiles spk', 'Laughs spk'])\n",
    "    axs[1].set_yticklabels(['Smiles lsn', 'Laughs lsn'])\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im_spk, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the figure\n",
    "    fig.suptitle(f'Mean mimicry probability heatmap during an interaction - {database}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For A/B:\n",
    "Laughs mimic laughs and smiles when spk mimics lsn.\n",
    "Laughs mimic smiles when lsn mimics spk and smiles mimic smiles. So smiles are more mimicked than laughs for lsn mimicking spk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For each entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_3 = []\n",
    "moyenne_prob_interaction_3 = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "entity_pairs = [(\"spk\", \"lsn\"), (\"lsn\", \"spk\")]\n",
    "\n",
    "# Iterate over each database\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Create a new dictionary to store entities grouped by expressions for each database\n",
    "    entities_by_expression = {}\n",
    "\n",
    "    # Group entities by expressions\n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        for entityA in entitiesA:\n",
    "            if expression_choiceA not in entities_by_expression:\n",
    "                entities_by_expression[expression_choiceA] = []\n",
    "            entities_by_expression[expression_choiceA].append(entityA)\n",
    "\n",
    "    # Iterate over expression pairs and entities for each database\n",
    "    for j, (expression_choiceA, entitiesA) in enumerate(entities_by_expression.items()):\n",
    "        for k, (expression_choiceB, entitiesB) in enumerate(entities_by_expression.items()):\n",
    "            # Create a matrix with zeros for spk and lsn categories\n",
    "            num_entities_A = len(entitiesA)\n",
    "            num_entities_B = len(entitiesB)\n",
    "            probabilities_matrix_1 = np.zeros((num_entities_A, num_entities_B))\n",
    "            probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "\n",
    "            # Track the current row and column index\n",
    "            current_row = 0\n",
    "            current_col = 0\n",
    "\n",
    "            for entityA in entitiesA:\n",
    "                for entityB in entitiesB:\n",
    "                    for pair_index, (entity1, entity2) in enumerate(entity_pairs):\n",
    "                        # Get the statistics for each entity of Role (spk or lsn)\n",
    "                        list_mimicry_SL_by_role = give_mimicry_folder4(databases_list, database.lower(), get_tier_from_tier, get_tier_from_tier, expression_choiceA, expression_choiceB, 'Role', entity1=entity1, entity2=entity2, filter='Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice)\n",
    "                        moyenne_prob_interaction_3 = 0\n",
    "                        for item in list_mimicry_SL_by_role:\n",
    "                            moyenne_prob_interaction_3 += item[1]\n",
    "\n",
    "                        moyenne_prob_interaction_3 /= len(list_mimicry_SL_by_role)\n",
    "\n",
    "                        if entity1 == \"spk\":\n",
    "                            probabilities_matrix_1[current_row, current_col] = moyenne_prob_interaction_3\n",
    "                        elif entity1 == \"lsn\":\n",
    "                            probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_3\n",
    "\n",
    "                    current_col += 1\n",
    "\n",
    "                current_row += 1\n",
    "                current_col = 0\n",
    "\n",
    "            # Select the appropriate subplots for each heatmap\n",
    "            ax_1 = axs[j, k * 2]\n",
    "            ax_2 = axs[j, k * 2 + 1]\n",
    "\n",
    "            # Create the heatmaps for spk and lsn\n",
    "            im_spk = ax_1.imshow(probabilities_matrix_1, cmap='YlGnBu', interpolation='nearest')\n",
    "            im_lsn = ax_2.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "            # Add the probability values within each square for spk and lsn\n",
    "            for x in range(num_entities_A):\n",
    "                for y in range(num_entities_B):\n",
    "                    text_color_spk = 'black'\n",
    "                    text_color_lsn = 'black'\n",
    "                    ax_1.text(y, x, f'{probabilities_matrix_1[x, y]:.5f}', ha='center', va='center', color=text_color_spk)\n",
    "                    ax_2.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color_lsn)\n",
    "\n",
    "            # Customize the plots for spk\n",
    "            ax_1.set_xticks(np.arange(num_entities_B))\n",
    "            ax_1.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax_1.set_yticks(np.arange(num_entities_A))\n",
    "            ax_1.set_yticklabels(entitiesA)\n",
    "            ax_1.set_xlabel(f\"{expression_choiceB} lsn\")\n",
    "            ax_1.set_ylabel(f\"{expression_choiceA} spk\")\n",
    "\n",
    "            # Customize the plots for lsn\n",
    "            ax_2.set_xticks(np.arange(num_entities_B))\n",
    "            ax_2.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax_2.set_yticks(np.arange(num_entities_A))\n",
    "            ax_2.set_yticklabels(entitiesA)\n",
    "            ax_2.set_xlabel(f\"{expression_choiceB} spk\")\n",
    "            ax_2.set_ylabel(f\"{expression_choiceA} lsn\")\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im_spk, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the heatmaps of each database\n",
    "    fig.suptitle(f'Mean mimicry probability heatmaps filtered by the role in the interaction for {database}', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For A/B:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCDB: In the case of laughs imitating smiles, the role does not impact the mimicry. Laughs are rarely high.\n",
    "Smiles mimicking smiles will often be of higher intensities, and more frequent in lsn mimicking spk.\n",
    "A laugh in the lsn will often be mimicked by a smile of greater intensity but by an equivalent laugh in the spk. Conversely, the lsn will more rarely mimic the spk's laughter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IFADV: In the case of a smile mimicking another smile, those of the lsn mimicking spk will be of less intensity and it will more easily mimic those of low intensity of the spk. On the other hand, spk will have stronger smiles when miming lsn.\n",
    "For laughs imitating smiles, the role has little impact. Lsn will mimic spk's smiles with laughs more frequently.\n",
    "Mimicked laughs are rare but a little more common from spk mimicking lsn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDC: Low and medium smiles are more often mimicked by smiles in the case of lsn mimicking spk. On the other hand, spk mimicking lsn will produce smiles of higher intensity mimicking other smiles.\n",
    "As for the other datasets, the roles do not have much impact on a laugh mimicking a smile. They will be a bit more expressive in spk mimicking lsn.\n",
    "The laughter of the spk will often be mimicked by medium smiles in the lsn but stronger intensities in the case of spk imitating lsn.\n",
    "Laughs mimicked by laughs will often be of higher intensities as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we observe that laughs mimic laughs when spk mimics lsn.\n",
    "Therefore, a possible interpretation for this exception is that spk is producing an utterance, expecting a reaction from lsn, so spk will mimic the laughs with real laughs and with a similar level as the lsnâ€™s. However, when lsn mimics spk, lsn could be producing fake laughs, and so laughs of lower levels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) A mimicking B "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at person A mimicking B in an interaction (so all first files in the pairs files mimicking second files in database order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B/A -> person A mimics person B\n",
    "mimic_choice2 = 'B/A' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mimicry Smiles vs Laughs (all entities) for each database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of the stats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database==databases_pairs[i].replace('_pairs','').upper():\n",
    "                databases_list=databases_pair_paths[databases_pairs[i]]\n",
    "    # Create a 2x2 matrix with zeros\n",
    "    probabilities_matrix = np.zeros((len(expressions), len(expressions)))\n",
    "    for j in range(len(expressions)):\n",
    "        expression_choiceA = expressions[j]\n",
    "        for k in range(len(expressions)):\n",
    "            expression_choiceB = expressions[k]\n",
    "            list_mimicry_SL = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, delta_t=delta, mimic_choice=mimic_choice2)\n",
    "            for item in list_mimicry_SL:\n",
    "                 moyenne_prob_interaction += item[1]\n",
    "            moyenne_prob_interaction = moyenne_prob_interaction/len(list_mimicry_SL)\n",
    "            probabilities_matrix[j, k] = moyenne_prob_interaction\n",
    "            moyenne_prob_interaction = 0\n",
    "\n",
    "    # Create a new figure for each database\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create the heatmap plot\n",
    "    im = ax.imshow(probabilities_matrix, cmap='YlGnBu', interpolation='nearest')\n",
    "    \n",
    "    # Add the probability values within each square\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color = 'black'  # Default text color\n",
    "            ax.text(y, x, f'{probabilities_matrix[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "    \n",
    "    # Customize the plot\n",
    "    fig.colorbar(im, ax=ax, label='Probability')\n",
    "    ax.set_xticks(range(len(expressions)))\n",
    "    ax.set_yticks(range(len(expressions)))\n",
    "    ax.set_xticklabels(expressions)\n",
    "    ax.set_yticklabels(expressions)\n",
    "    ax.set_title(f'Mean mimicry probability heatmap of Smiles or Laughs following Smiles or Laughs in an interaction - {database}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the stats:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For B\\A: We observe that smiles are mostly mimicked by smiles and laughs, while laughs are mostly mimicked by laughs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mimicry Smiles vs Laughs (per entity) for each database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of the stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_2 = []\n",
    "moyenne_prob_interaction_2 = 0\n",
    "\n",
    "# Iterate over each database\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Create a new dictionary to store entities grouped by expressions for each database\n",
    "    entities_by_expression = {}\n",
    "\n",
    "    # Group entities by expressions\n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        for entityA in entitiesA:\n",
    "            if expression_choiceA not in entities_by_expression:\n",
    "                entities_by_expression[expression_choiceA] = []\n",
    "            entities_by_expression[expression_choiceA].append(entityA)\n",
    "\n",
    "    # Iterate over expression pairs and entities for each database\n",
    "    for j, (expression_choiceA, entitiesA) in enumerate(entities_by_expression.items()):\n",
    "        for k, (expression_choiceB, entitiesB) in enumerate(entities_by_expression.items()):\n",
    "            # Create a matrix with zeros\n",
    "            num_entities_A = len(entitiesA)\n",
    "            num_entities_B = len(entitiesB)\n",
    "            probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "\n",
    "            # Track the current row and column index\n",
    "            current_row = 0\n",
    "            current_col = 0\n",
    "\n",
    "            for entityA in entitiesA:\n",
    "                for entityB in entitiesB:\n",
    "                    list_mimicry_SL_entity = give_mimicry_folder2(databases_list, database.lower(), get_tier_dict_conv_folder, get_tier_dict_conv_folder, expression_choiceA, expression_choiceB, 'Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice2)\n",
    "\n",
    "                    for item in list_mimicry_SL_entity:\n",
    "                        moyenne_prob_interaction_2 += item[1]\n",
    "\n",
    "                    moyenne_prob_interaction_2 = moyenne_prob_interaction_2 / len(list_mimicry_SL_entity)\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_2\n",
    "                    moyenne_prob_interaction_2 = 0\n",
    "\n",
    "                    current_col += 1\n",
    "\n",
    "                current_row += 1\n",
    "                current_col = 0\n",
    "\n",
    "            # Select the appropriate subplot for each heatmap\n",
    "            ax = axs[j, k]\n",
    "\n",
    "            # Create the heatmap plot\n",
    "            im = ax.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "            # Add the probability values within each square\n",
    "            for x in range(num_entities_A):\n",
    "                for y in range(num_entities_B):\n",
    "                    text_color = 'black'\n",
    "                    ax.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color)\n",
    "\n",
    "            # Customize the plot\n",
    "            ax.set_xticks(np.arange(num_entities_B))\n",
    "            ax.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax.set_yticks(np.arange(num_entities_A))\n",
    "            ax.set_yticklabels(entitiesA)\n",
    "            ax.set_xlabel(expression_choiceB)\n",
    "            ax.set_ylabel(expression_choiceA)\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the heatmaps of each database\n",
    "    fig.suptitle(f'Mean mimicry probability heatmaps during an interaction for {database}', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the stats:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For B/A : When smiles mimic smiles, the levels of smiles tend to be lower for IFADV and NDC, while CCDB is more variable. \n",
    "When laughs mimic smiles, the levels of smiles are similar.\n",
    "When smiles mimic laughs, the levels of laughs are lower generaly or similar.\n",
    "When laughs mimic laughs, the levels of laughs are similar or lower (50% medium mimic high laughs for NDC).\n",
    "We have really few information for laughs mimicking laughs and smiles mimicking laughs for IFADV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered by role"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For all entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "entity_pairs = [(\"spk\", \"lsn\"), (\"lsn\", \"spk\")]\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database==databases_pairs[i].replace('_pairs','').upper():\n",
    "                databases_list=databases_pair_paths[databases_pairs[i]]\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "\n",
    "    # Create a 2x2 matrix with zeros\n",
    "    probabilities_matrix_1 = np.zeros((len(expressions), len(expressions)))\n",
    "    probabilities_matrix_2 = np.zeros((len(expressions), len(expressions)))\n",
    "    for j in range(len(expressions)):\n",
    "        expression_choiceA = expressions[j]\n",
    "        for k in range(len(expressions)):\n",
    "            expression_choiceB = expressions[k]\n",
    "            for pair_index, (entityA, entityB) in enumerate(entity_pairs):\n",
    "                # Get the statistics for each entity of Role (spk or lsn)\n",
    "                list_mimicry_SL_by_role = give_mimicry_folder4(databases_list, database.lower(), get_tier_from_tier, get_tier_from_tier, expression_choiceA, expression_choiceB, tier_filter='Role', entity1=entityA, entity2=entityB, delta_t=delta, mimic_choice=mimic_choice2)\n",
    "                moyenne_prob_interaction = 0\n",
    "                for item in list_mimicry_SL_by_role:\n",
    "                    moyenne_prob_interaction += item[1]\n",
    "                moyenne_prob_interaction = moyenne_prob_interaction/len(list_mimicry_SL_by_role)\n",
    "                if entityA == \"spk\":\n",
    "                    probabilities_matrix_1[current_row, current_col] = moyenne_prob_interaction\n",
    "                elif entityA == \"lsn\":\n",
    "                    probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction\n",
    "\n",
    "            current_col += 1\n",
    "\n",
    "        current_row += 1\n",
    "        current_col = 0\n",
    "    # Create the heatmaps for spk and lsn\n",
    "    im_spk = axs[0].imshow(probabilities_matrix_1, cmap='YlGnBu', interpolation='nearest')\n",
    "    im_lsn = axs[1].imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "    # Add the probability values within each square for spk\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color_spk = 'black'\n",
    "            axs[0].text(y, x, f'{probabilities_matrix_1[x, y]:.5f}', ha='center', va='center', color=text_color_spk)\n",
    "\n",
    "    # Add the probability values within each square for lsn\n",
    "    for x in range(len(expressions)):\n",
    "        for y in range(len(expressions)):\n",
    "            text_color_lsn = 'black'\n",
    "            axs[1].text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color_lsn)\n",
    "\n",
    "    # Customize the plots for spk and lsn\n",
    "    axs[0].set_xticks(range(len(expressions)))\n",
    "    axs[0].set_yticks(range(len(expressions)))\n",
    "    axs[0].set_xticklabels(['Smiles lsn', 'Laughs lsn'])\n",
    "    axs[0].set_yticklabels(['Smiles spk', 'Laughs spk'])\n",
    "    \n",
    "\n",
    "    axs[1].set_xticks(range(len(expressions)))\n",
    "    axs[1].set_yticks(range(len(expressions)))\n",
    "    axs[1].set_xticklabels(['Smiles spk', 'Laughs spk'])\n",
    "    axs[1].set_yticklabels(['Smiles lsn', 'Laughs lsn'])\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im_spk, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the figure\n",
    "    fig.suptitle(f'Mean mimicry probability heatmap during an interaction - {database}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For B/A: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix_3 = []\n",
    "moyenne_prob_interaction_3 = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "entity_pairs = [(\"spk\", \"lsn\"), (\"lsn\", \"spk\")]\n",
    "\n",
    "# Iterate over each database\n",
    "for i, database in enumerate(databases_name):\n",
    "    if database == databases_pairs[i].replace('_pairs', '').upper():\n",
    "        databases_list = databases_pair_paths[databases_pairs[i]]\n",
    "\n",
    "    # Create a new figure and axes\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "    # Create a new dictionary to store entities grouped by expressions for each database\n",
    "    entities_by_expression = {}\n",
    "\n",
    "    # Group entities by expressions\n",
    "    for expression_choiceA in expressions:\n",
    "        entitiesA = tier_lists[expression_choiceA]\n",
    "        for entityA in entitiesA:\n",
    "            if expression_choiceA not in entities_by_expression:\n",
    "                entities_by_expression[expression_choiceA] = []\n",
    "            entities_by_expression[expression_choiceA].append(entityA)\n",
    "\n",
    "    # Iterate over expression pairs and entities for each database\n",
    "    for j, (expression_choiceA, entitiesA) in enumerate(entities_by_expression.items()):\n",
    "        for k, (expression_choiceB, entitiesB) in enumerate(entities_by_expression.items()):\n",
    "            # Create a matrix with zeros for spk and lsn categories\n",
    "            num_entities_A = len(entitiesA)\n",
    "            num_entities_B = len(entitiesB)\n",
    "            probabilities_matrix_1 = np.zeros((num_entities_A, num_entities_B))\n",
    "            probabilities_matrix_2 = np.zeros((num_entities_A, num_entities_B))\n",
    "\n",
    "            # Track the current row and column index\n",
    "            current_row = 0\n",
    "            current_col = 0\n",
    "\n",
    "            for entityA in entitiesA:\n",
    "                for entityB in entitiesB:\n",
    "                    for pair_index, (entity1, entity2) in enumerate(entity_pairs):\n",
    "                        # Get the statistics for each entity of Role (spk or lsn)\n",
    "                        list_mimicry_SL_by_role = give_mimicry_folder4(databases_list, database.lower(), get_tier_from_tier, get_tier_from_tier, expression_choiceA, expression_choiceB, 'Role', entity1=entity1, entity2=entity2, filter='Intensity', label=[str.lower(entityA), str.lower(entityB)], delta_t=delta, mimic_choice=mimic_choice2)\n",
    "                        moyenne_prob_interaction_3 = 0\n",
    "                        for item in list_mimicry_SL_by_role:\n",
    "                            moyenne_prob_interaction_3 += item[1]\n",
    "\n",
    "                        moyenne_prob_interaction_3 /= len(list_mimicry_SL_by_role)\n",
    "\n",
    "                        if entity1 == \"spk\":\n",
    "                            probabilities_matrix_1[current_row, current_col] = moyenne_prob_interaction_3\n",
    "                        elif entity1 == \"lsn\":\n",
    "                            probabilities_matrix_2[current_row, current_col] = moyenne_prob_interaction_3\n",
    "\n",
    "                    current_col += 1\n",
    "\n",
    "                current_row += 1\n",
    "                current_col = 0\n",
    "\n",
    "            # Select the appropriate subplots for each heatmap\n",
    "            ax_1 = axs[j, k * 2]\n",
    "            ax_2 = axs[j, k * 2 + 1]\n",
    "\n",
    "            # Create the heatmaps for spk and lsn\n",
    "            im_spk = ax_1.imshow(probabilities_matrix_1, cmap='YlGnBu', interpolation='nearest')\n",
    "            im_lsn = ax_2.imshow(probabilities_matrix_2, cmap='YlGnBu', interpolation='nearest')\n",
    "\n",
    "            # Add the probability values within each square for spk and lsn\n",
    "            for x in range(num_entities_A):\n",
    "                for y in range(num_entities_B):\n",
    "                    text_color_spk = 'black'\n",
    "                    text_color_lsn = 'black'\n",
    "                    ax_1.text(y, x, f'{probabilities_matrix_1[x, y]:.5f}', ha='center', va='center', color=text_color_spk)\n",
    "                    ax_2.text(y, x, f'{probabilities_matrix_2[x, y]:.5f}', ha='center', va='center', color=text_color_lsn)\n",
    "\n",
    "            # Customize the plots for spk\n",
    "            ax_1.set_xticks(np.arange(num_entities_B))\n",
    "            ax_1.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax_1.set_yticks(np.arange(num_entities_A))\n",
    "            ax_1.set_yticklabels(entitiesA)\n",
    "            ax_1.set_xlabel(f\"{expression_choiceB} lsn\")\n",
    "            ax_1.set_ylabel(f\"{expression_choiceA} spk\")\n",
    "\n",
    "            # Customize the plots for lsn\n",
    "            ax_2.set_xticks(np.arange(num_entities_B))\n",
    "            ax_2.set_xticklabels(entitiesB, rotation=90)\n",
    "            ax_2.set_yticks(np.arange(num_entities_A))\n",
    "            ax_2.set_yticklabels(entitiesA)\n",
    "            ax_2.set_xlabel(f\"{expression_choiceB} spk\")\n",
    "            ax_2.set_ylabel(f\"{expression_choiceA} lsn\")\n",
    "\n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im_spk, ax=axs, label='Probability')\n",
    "\n",
    "    # Add a common title for the heatmaps of each database\n",
    "    fig.suptitle(f'Mean mimicry probability heatmaps filtered by the role in the interaction for {database}', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For B/A: With a delta=0, there is no mimicry of smiles by laughs and vice versa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-SMILE AND LAUGH SEQUENCES (intra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we study the temporal sequence patterns of S&L produced during an entire interaction (i.e., oneâ€™s own S&L sequence pattern, not considering their interlocutorâ€™s).\n",
    "For this, we consider the S&L directly following any smile or laugh. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track of previous expression for each dataset of each individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "expression_pairs = [(\"Smiles_0\", \"Smiles_0\"), (\"Smiles_0\", \"Laughs_0\"), (\"Laughs_0\", \"Laughs_0\"), (\"Laughs_0\", \"Smiles_0\")]\n",
    "\n",
    "# Iterate over the datasets\n",
    "for dataset_index, database in enumerate(databases_name):\n",
    "    # Create a new figure and axes for the current dataset\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "    \n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "    \n",
    "    # Iterate over the expression pairs for the heatmaps\n",
    "    for pair_index, (expression_choiceA, expression_choiceB) in enumerate(expression_pairs):\n",
    "        # Get the appropriate intensity labels based on the expressions\n",
    "        intensity_labelsT = copy.deepcopy(smiles_intensities) if expression_choiceA == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC = copy.deepcopy(smiles_intensities) if expression_choiceB == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC.append(\"null\")\n",
    "        \n",
    "        # Create a 2x2 matrix with zeros\n",
    "        probabilities_matrix_intensity = np.zeros((len(intensity_labelsT), len(intensity_labelsC)))\n",
    "        \n",
    "        list_mimicry_TC = expression_track_byI(expression_choiceA, expression_choiceB, DIR, [database], tier_lists)\n",
    "        list_mimicry_TC_prev = list_mimicry_TC[0]  # Previous expression DataFrame\n",
    "        \n",
    "        # Create the heatmap for previous expression\n",
    "        ax = axs[current_row, current_col]\n",
    "        for i, intensityC in enumerate(intensity_labelsC):\n",
    "            for j, intensityT in enumerate(intensity_labelsT):\n",
    "                try:\n",
    "                    filtered_list_prev = list_mimicry_TC_prev[\n",
    "                        (list_mimicry_TC_prev['Intensityp'] == intensityC) &\n",
    "                        (list_mimicry_TC_prev[f'Current_level_{expression_choiceB}p'] == intensityT)\n",
    "                    ]\n",
    "                    percentage_prev = filtered_list_prev['Percentagep'].values[0] \n",
    "                    probabilities_matrix_intensity[j, i] = percentage_prev / 100.0\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        # Plot the heatmap\n",
    "        im = ax.imshow(probabilities_matrix_intensity, cmap='YlGnBu', interpolation='nearest')\n",
    "        # Add the text for each cell\n",
    "        for i in range(len(intensity_labelsC)):\n",
    "            for j in range(len(intensity_labelsT)):\n",
    "                text = ax.text(i, j, f\"{probabilities_matrix_intensity[j, i]:.5f}\", ha='center', va='center', color='black')\n",
    "\n",
    "        # Set the title for the current heatmap\n",
    "        ax.set_xticks(range(len(intensity_labelsC)))\n",
    "        ax.set_yticks(range(len(intensity_labelsT)))\n",
    "        ax.set_xticklabels(intensity_labelsC)\n",
    "        ax.set_yticklabels(intensity_labelsT)\n",
    "        ax.set_xlabel(f\"{expression_choiceA} (Current)\")\n",
    "        ax.set_ylabel(f\"{expression_choiceB} (Previous)\")\n",
    "        \n",
    "        # Update the current row and column index\n",
    "        current_col += 1\n",
    "        if current_col == 2:\n",
    "            current_row += 1\n",
    "            current_col = 0\n",
    "    \n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im, ax=axs, label='Probability')\n",
    "\n",
    "    # Set the title for the figure based on the dataset\n",
    "    fig.suptitle(f\"Probabilities of Previous Expression (Rows) Followed by Another Expression (Current) for dataset: {database}\", fontsize=16)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track of next expression for each dataset of each individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "expression_pairs = [(\"Smiles_0\", \"Smiles_0\"), (\"Smiles_0\", \"Laughs_0\"), (\"Laughs_0\", \"Laughs_0\"), (\"Laughs_0\", \"Smiles_0\")]\n",
    "\n",
    "# Iterate over the datasets\n",
    "for dataset_index, database in enumerate(databases_name):\n",
    "    # Create a new figure and axes for the current dataset\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "    \n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "    \n",
    "    # Iterate over the expression pairs for the heatmaps\n",
    "    for pair_index, (expression_choiceA, expression_choiceB) in enumerate(expression_pairs):\n",
    "        # Get the appropriate intensity labels based on the expressions\n",
    "        intensity_labelsT = copy.deepcopy(smiles_intensities) if expression_choiceA == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC = copy.deepcopy(smiles_intensities) if expression_choiceB == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC.append(\"null\")\n",
    "        \n",
    "        # Create a 2x2 matrix with zeros\n",
    "        probabilities_matrix_intensity = np.zeros((len(intensity_labelsT), len(intensity_labelsC)))\n",
    "        \n",
    "        list_mimicry_TC = expression_track_byI(expression_choiceA, expression_choiceB, DIR, [database], tier_lists)\n",
    "        list_mimicry_TC_next = list_mimicry_TC[1]  # Next expression DataFrame\n",
    "        \n",
    "        # Create the heatmap for next expression\n",
    "        ax = axs[current_row, current_col]\n",
    "        for i, intensityC in enumerate(intensity_labelsC):\n",
    "            for j, intensityT in enumerate(intensity_labelsT):\n",
    "                try :\n",
    "                    filtered_list_next = list_mimicry_TC_next[\n",
    "                        (list_mimicry_TC_next['Intensityf'] == intensityC) &\n",
    "                        (list_mimicry_TC_next[f'Current_level_{expression_choiceB}f'] == intensityT)\n",
    "                    ]\n",
    "                    percentage_next = filtered_list_next['Percentagef'].values[0]\n",
    "                    probabilities_matrix_intensity[j, i] = percentage_next / 100.0\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        # Plot the heatmap\n",
    "        im = ax.imshow(probabilities_matrix_intensity, cmap='YlGnBu', interpolation='nearest')\n",
    "        # Add the text for each cell\n",
    "        for i in range(len(intensity_labelsC)):\n",
    "            for j in range(len(intensity_labelsT)):\n",
    "                text = ax.text(i, j, f\"{probabilities_matrix_intensity[j, i]:.5f}\", ha='center', va='center', color='black')\n",
    "\n",
    "        # Set the title for the current heatmap\n",
    "        ax.set_xticks(range(len(intensity_labelsC)))\n",
    "        ax.set_yticks(range(len(intensity_labelsT)))\n",
    "        ax.set_xticklabels(intensity_labelsC)\n",
    "        ax.set_yticklabels(intensity_labelsT)\n",
    "        ax.set_xlabel(f\"{expression_choiceA} (Current)\")\n",
    "        ax.set_ylabel(f\"{expression_choiceB} (Next)\")\n",
    "        \n",
    "        # Update the current row and column index\n",
    "        current_col += 1\n",
    "        if current_col == 2:\n",
    "            current_row += 1\n",
    "            current_col = 0\n",
    "    \n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im, ax=axs, label='Probability')\n",
    "\n",
    "    # Set the title for the figure based on the dataset\n",
    "    fig.suptitle(f\"Probabilities of Next Expression (Rows) Followed by Another Expression (Current) for dataset: {database}\", fontsize=16)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track of expression for each dataset of each individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_matrix = []\n",
    "moyenne_prob_interaction = 0\n",
    "# Define the pairs of expressions for the heatmaps\n",
    "expression_pairs = [(\"Smiles_0\", \"Smiles_0\"), (\"Smiles_0\", \"Laughs_0\"), (\"Laughs_0\", \"Laughs_0\"), (\"Laughs_0\", \"Smiles_0\")]\n",
    "\n",
    "# Iterate over the datasets\n",
    "for dataset_index, database in enumerate(databases_name):\n",
    "    # Create a new figure and axes for the current dataset\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), constrained_layout=True)\n",
    "    \n",
    "    # Track the current row and column index\n",
    "    current_row = 0\n",
    "    current_col = 0\n",
    "    \n",
    "    # Iterate over the expression pairs for the heatmaps\n",
    "    for pair_index, (expression_choiceA, expression_choiceB) in enumerate(expression_pairs):\n",
    "        # Get the appropriate intensity labels based on the expressions\n",
    "        intensity_labelsT = copy.deepcopy(smiles_intensities) if expression_choiceA == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC = copy.deepcopy(smiles_intensities) if expression_choiceB == \"Smiles_0\" else copy.deepcopy(laughs_intensities)\n",
    "        intensity_labelsC.append(\"null\")\n",
    "        \n",
    "        # Create a 2x2 matrix with zeros\n",
    "        probabilities_matrix_intensity = np.zeros((len(intensity_labelsT), len(intensity_labelsC)))\n",
    "        \n",
    "        list_mimicry_TC = expression_track_byI(expression_choiceA, expression_choiceB, DIR, [database], tier_lists)\n",
    "        list_mimicry_TC_prev = list_mimicry_TC[0]  # Previous expression DataFrame\n",
    "        list_mimicry_TC_next = list_mimicry_TC[1]  # Next expression DataFrame\n",
    "        \n",
    "        # Create the heatmap for combined expressions\n",
    "        ax = axs[current_row, current_col]\n",
    "        for i, intensityC in enumerate(intensity_labelsC):\n",
    "            for j, intensityT in enumerate(intensity_labelsT):\n",
    "                try :\n",
    "                    filtered_list_prev = list_mimicry_TC_prev[\n",
    "                        (list_mimicry_TC_prev['Intensityp'] == intensityC) &\n",
    "                        (list_mimicry_TC_prev[f'Current_level_{expression_choiceB}p'] == intensityT)\n",
    "                    ]\n",
    "                    percentage_prev2 = filtered_list_prev['Percentagep'].values[0]\n",
    "                    \n",
    "                    filtered_list_next = list_mimicry_TC_next[\n",
    "                        (list_mimicry_TC_next['Intensityf'] == intensityC) &\n",
    "                        (list_mimicry_TC_next[f'Current_level_{expression_choiceB}f'] == intensityT)\n",
    "                    ]\n",
    "                    percentage_next2 = filtered_list_next['Percentagef'].values[0]\n",
    "                    # Average the percentages for previous and next expressions\n",
    "                    combined_percentage = (percentage_prev2 + percentage_next2) / 2\n",
    "                    probabilities_matrix_intensity[j, i] = combined_percentage / 100.0\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        # Plot the heatmap\n",
    "        im = ax.imshow(probabilities_matrix_intensity, cmap='YlGnBu', interpolation='nearest')\n",
    "        # Add the text for each cell\n",
    "        for i in range(len(intensity_labelsC)):\n",
    "            for j in range(len(intensity_labelsT)):\n",
    "                text = ax.text(i, j, f\"{probabilities_matrix_intensity[j, i]:.5f}\", ha='center', va='center', color='black')\n",
    "\n",
    "        # Set the title for the current heatmap\n",
    "        ax.set_xticks(range(len(intensity_labelsC)))\n",
    "        ax.set_yticks(range(len(intensity_labelsT)))\n",
    "        ax.set_xticklabels(intensity_labelsC)\n",
    "        ax.set_yticklabels(intensity_labelsT)\n",
    "        ax.set_xlabel(f\"{expression_choiceA} (Check)\")\n",
    "        ax.set_ylabel(f\"{expression_choiceB} (Track)\")\n",
    "        \n",
    "        # Update the current row and column index\n",
    "        current_col += 1\n",
    "        if current_col == 2:\n",
    "            current_row += 1\n",
    "            current_col = 0\n",
    "    \n",
    "    # Add a common colorbar for the heatmaps of each database\n",
    "    fig.colorbar(im, ax=axs, label='Probability')\n",
    "\n",
    "    # Set the title for the figure based on the dataset\n",
    "    fig.suptitle(f\"Probabilities that smiles or laughs (columns) follow smiles or laughs (rows) at different intensities. for dataset: {database}\", fontsize=16)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first note that, in general, laughs and smiles are mostly followed by smiles.\n",
    "We can see that laughs are rarely followed by no laughs and mostly followed by laughs of similar levels.\n",
    "Due to the rare occurrence of laughs of high levels compared to lower levels, we rarely observe laughs following higher levels of smiles.\n",
    "But we can observe with high probability, laughs with higher levels follow smiles with higher levels.\n",
    "When smiles follow smiles, we can see that the lower levels (subtle and low) are mostly followed by the levels directly above them (low and medium respectively) and the higher levels (medium and high) by the ones directly below them (medium and low respectively, even subtle). When laughs follow laughs, the successive laughs have similar levels.\n",
    "The smile-laugh continuum suggests that S&L can be represented on the same scale.S&L (especially laughs) rarely occur without any surrounding S&L, and that a relationship exists between the S&L intensity levels when these form sequences. In all cases, the most probable levels following other levels are the closest ones. There is thus, in a sequence of S&L, no sudden variation across levels but rather gradual variation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potato",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
